Add loading model for evaluation
use apex - move optimizer out of mcts and pass directly
profile the script
add better logging for multiprocessing
change convolutional layer - test 4 or 5 size
add dropout - test done
allow changing of buffer size when loading
debug model - show loss?
increase training window slowly? maybe

add position deduplication?






#write full stack trace error
#add seperate resume triggers for memory/model



add multithreading capability
check on connect 4
add async self-play - network training
add skip connection
Save memory buffer as well as model weights






figure out why weights are increasing (tried clamping to fix?)
Model overfitting - think about dropout layer, prioritized experience replay

#TODO make sure copies are consistent

add evaluation against random player

Add learning rate
add target network (done)
add prioritized experience replay (done)
save models (done)
Think about evalution of models
add dropout layers (done)
add gpu(done)
optimize code for gpu
pararelize cpu code

maybe try softmax instead of epsilon greedy (for evaluation?)

#add higher order logic on self play (MCTS)




change from q learning to something else (td lambda? n step tree backup?)
convert everything to tensor before it hits networK???????????????
